{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Setup & Dataset Import"
      ],
      "metadata": {
        "id": "ay9ttw0IlPZ2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JqYY0cwIkJmq"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import ToTensor\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yT3vR52KNjgA",
        "outputId": "a5978984-d228-42ca-d7f3-917eee865305"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import MNIST\n",
        "train_data = datasets.MNIST(\n",
        "    root = './data',\n",
        "    train = True,\n",
        "    transform = ToTensor(),\n",
        "    download = True,\n",
        ")\n",
        "test_data = datasets.MNIST(\n",
        "    root = './data',\n",
        "    train = False,\n",
        "    transform = ToTensor()\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGYNvwIhker4",
        "outputId": "e3feb398-482d-4839-ed4f-4b761a155eb1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 236899989.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 35357762.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 65752287.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 19088706.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataloader\n",
        "loaders = {\n",
        "    'train' : torch.utils.data.DataLoader(train_data,\n",
        "                                          batch_size=1,\n",
        "                                          shuffle=True,\n",
        "                                          num_workers=1),\n",
        "\n",
        "    'test'  : torch.utils.data.DataLoader(test_data,\n",
        "                                          batch_size=1,\n",
        "                                          shuffle=False,\n",
        "                                          num_workers=1),\n",
        "}\n",
        "loaders"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4C-DcpX9p2o",
        "outputId": "b85b7a88-7e2a-4738-ed7a-f69dfdd88ac3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': <torch.utils.data.dataloader.DataLoader at 0x7f129b676500>,\n",
              " 'test': <torch.utils.data.dataloader.DataLoader at 0x7f129b675240>}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Construct Negative Examples for Unsupervised Training\n",
        "\n"
      ],
      "metadata": {
        "id": "8xEIHA2ZN1wj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filter = torch.tensor([[0.0625,0.125,0.0625],[0.125,0.25,0.125],[0.0625,0.125,0.0625]])\n",
        "\n",
        "def blur(img,filter):\n",
        "  # blur img using filter\n",
        "  # params: filter --> torch.tensor(2*radius+1,2*radius+1)\n",
        "  m,n = img.shape\n",
        "  radius = (filter.shape[0]-1)//2\n",
        "  new_img = torch.zeros(m,n)\n",
        "  for i in range(m):\n",
        "    for j in range(n):\n",
        "      top,left,bottom,right = max(0,i-radius),max(0,j-radius),min(m-1,i+radius),min(m-1,j+radius)\n",
        "      new_img[i][j] = sum([img[x][y]*filter[x-i+radius][y-j+radius]\n",
        "                           for y in range(left,right+1) for x in range(top,bottom+1)])\n",
        "  return new_img\n",
        "\n",
        "def generate_negative_example():\n",
        "  # construct a negative example for unsupervised case (3.2 in paper)\n",
        "  mask = (torch.rand(28,28) > 0.5).long() # initiate as random bit image\n",
        "\n",
        "  for i in range(6): # repeat blurring 6 times\n",
        "    mask = blur(mask,filter)\n",
        "\n",
        "  mask = (mask > 0.5).long() # mask\n",
        "\n",
        "  index1,index2 = torch.randint(len(train_data),(2,))\n",
        "  return (mask * train_data[index1][0] + (1-mask) * train_data[index2][0])"
      ],
      "metadata": {
        "id": "rfySAAjudWtk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Definition\n",
        "\n"
      ],
      "metadata": {
        "id": "fxx1HhrVZU8b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# single-layer NN\n",
        "class one_layer_net(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, in_size, out_size):\n",
        "        super(one_layer_net, self).__init__()\n",
        "\n",
        "        # hidden layer\n",
        "        self.layer = torch.nn.Sequential(\n",
        "            torch.nn.Flatten(), # nn.Flatten to standardize input shape\n",
        "            torch.nn.Linear(in_size, out_size),\n",
        "            torch.nn.ReLU() # activation function\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "      return self.layer(x)"
      ],
      "metadata": {
        "id": "dOcFixAKTEOh"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# full network\n",
        "class net(torch.nn.Module):\n",
        "  # Constructor\n",
        "  def __init__(self,in_size):\n",
        "    super(net, self).__init__()\n",
        "    self.layer1 = one_layer_net(in_size,2000)\n",
        "    self.layer2 = one_layer_net(2000,2000)\n",
        "    self.layer3 = one_layer_net(2000,2000)\n",
        "    self.layer4 = one_layer_net(2000,2000)\n",
        "    self.ln = torch.nn.LayerNorm(2000) # layernorm\n",
        "\n",
        "    # softmax layer for hard negative label generation\n",
        "    self.out_layer = torch.nn.Linear(6000, 10)\n",
        "    self.sm = torch.nn.Softmax(dim=0) # softmax\n",
        "\n",
        "    self.layers = [self.layer1,self.layer2,self.layer3,self.layer4,self.out_layer]\n",
        "\n",
        "  def forward(self,x):\n",
        "    # x-->tensor (channel,height,width) or (height,width)\n",
        "    interms = []\n",
        "    interm = x.detach().clone().unsqueeze(0)\n",
        "\n",
        "    for index in range(len(self.layers)-1):\n",
        "      layer = self.layers[index] # linear layer\n",
        "      interm = self.ln(layer(interm)) # layer-norm\n",
        "      interms.append(interm.detach().clone()) # store normalized activity\n",
        "\n",
        "    final_input = torch.cat(interms[1:],dim=1)\n",
        "    res = self.out_layer(final_input) # final output layer\n",
        "    return res\n",
        "\n",
        "  def predict(self,x):\n",
        "    # x-->tensor (channel,height,width) or (height,width)\n",
        "\n",
        "    accumulate_goodness = np.zeros(10)\n",
        "    for i in range(10): # iterate through all labels\n",
        "      interm = x.detach().clone().squeeze()\n",
        "\n",
        "      # update one-hot label encoding\n",
        "      interm[0][:10] = 0\n",
        "      interm[0][i] = 1\n",
        "\n",
        "      for index in range(len(self.layers)-1):\n",
        "        interm = interm.unsqueeze(0)\n",
        "        layer = self.layers[index]\n",
        "        interm = layer(interm)\n",
        "\n",
        "        if index > 0: # accumulate goodness for all but first layers\n",
        "          accumulate_goodness[i] += self.goodness(interm)\n",
        "\n",
        "        if index + 1 < len(self.layers): # layernorm\n",
        "          interm = self.ln(interm)\n",
        "    return np.argmax(accumulate_goodness)\n",
        "\n",
        "  def goodness(self,x):\n",
        "    # goodness functions--sum of squares\n",
        "    return torch.sum(torch.square(x))\n",
        "\n",
        "  def construct_supervised_example(self,x,label,positive=True):\n",
        "    # construct positive or negative examples for supervised training\n",
        "    # x-->tensor (channel,height,width)\n",
        "    # label-->int\n",
        "    ans = x.detach().clone().squeeze()\n",
        "    if positive:\n",
        "      # one-hot encoding\n",
        "      ans[0][:10] = 0\n",
        "      ans[0][label] = 1\n",
        "    else:\n",
        "      ans[0][:10] = 0.1 # initialize neutral label\n",
        "\n",
        "      # run forward pass\n",
        "      labels = self.forward(ans).squeeze()\n",
        "      labels[label] = -float('inf')\n",
        "      prob = self.sm(labels).cpu() # probability distribution to choose label\n",
        "\n",
        "      # generate negative example from forward pass\n",
        "      r = np.random.choice(np.arange(10),p=prob.detach().numpy())\n",
        "      ans[0][:10] = 0\n",
        "      ans[0][r] = 1\n",
        "\n",
        "    return ans.unsqueeze(0) # in shape (C,H,W)"
      ],
      "metadata": {
        "id": "0iLwMtYODMgb"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training"
      ],
      "metadata": {
        "id": "Hi5CDidzl5jN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create model\n",
        "model = net(784)\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "mXS93nQJOmoD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0870106f-5325-41b4-d655-2547362940eb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "net(\n",
              "  (layer1): one_layer_net(\n",
              "    (layer): Sequential(\n",
              "      (0): Flatten(start_dim=1, end_dim=-1)\n",
              "      (1): Linear(in_features=784, out_features=2000, bias=True)\n",
              "      (2): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (layer2): one_layer_net(\n",
              "    (layer): Sequential(\n",
              "      (0): Flatten(start_dim=1, end_dim=-1)\n",
              "      (1): Linear(in_features=2000, out_features=2000, bias=True)\n",
              "      (2): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (layer3): one_layer_net(\n",
              "    (layer): Sequential(\n",
              "      (0): Flatten(start_dim=1, end_dim=-1)\n",
              "      (1): Linear(in_features=2000, out_features=2000, bias=True)\n",
              "      (2): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (layer4): one_layer_net(\n",
              "    (layer): Sequential(\n",
              "      (0): Flatten(start_dim=1, end_dim=-1)\n",
              "      (1): Linear(in_features=2000, out_features=2000, bias=True)\n",
              "      (2): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (ln): LayerNorm((2000,), eps=1e-05, elementwise_affine=True)\n",
              "  (out_layer): Linear(in_features=6000, out_features=10, bias=True)\n",
              "  (sm): Softmax(dim=0)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# apply xavier initialization on weights\n",
        "def init_weights(m):\n",
        "    if isinstance(m, nn.Linear):\n",
        "        torch.nn.init.xavier_uniform_(m.weight)\n",
        "        m.bias.data.fill_(0.01)"
      ],
      "metadata": {
        "id": "kC0QvPgPfknW"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# design loss function\n",
        "def goodness_loss(pos_goodness,neg_goodness):\n",
        "  # loss function intended for maximizing goodness in positive examples\n",
        "  # and minimizing goodness in negative examples\n",
        "  return torch.log(1+torch.exp(neg_goodness-pos_goodness))\n",
        "\n",
        "\n",
        "# CrossEntropyLoss for final softmax layer optimization\n",
        "ceLoss = torch.nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "-KK7uRkQMKTi"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train model\n",
        "\n",
        "def train(num_epochs, model, loaders, supervised = True):\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    # variables for training output\n",
        "    total_step = len(loaders['train'])\n",
        "    total_pos_goodness,total_neg_goodness = [0]*(len(model.layers)-1),[0]*(len(model.layers)-1)\n",
        "    total_loss = [0]*(len(model.layers))\n",
        "\n",
        "    optimizers = []\n",
        "    lrs = [1e-3,3e-4,1e-4,5e-5,1e-3]\n",
        "    # initialize each layer\n",
        "    for index in range(len(model.layers)):\n",
        "      # layer & training initialization\n",
        "      layer = model.layers[index]\n",
        "      layer.apply(init_weights)\n",
        "      optimizers.append(torch.optim.SGD(layer.parameters(), lr=lrs[index],weight_decay=1e-5))\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for i,(x,label) in enumerate(loaders['train']): # iterate through dataset\n",
        "\n",
        "            x = x.to(device)\n",
        "            if not supervised: # unsupervised training input\n",
        "              pos_img = x.squeeze()\n",
        "              neg_img = generate_negative_example().squeeze().to(device)\n",
        "            else: # supervised learning input\n",
        "              pos_img = model.construct_supervised_example(x,label[0],True)\n",
        "              neg_img = model.construct_supervised_example(x,label[0],False)\n",
        "\n",
        "            # intermediate variables\n",
        "            pos_interms = []\n",
        "            neg_interms = []\n",
        "            pos_interm = pos_img.clone()\n",
        "            neg_interm = neg_img.clone()\n",
        "\n",
        "            # iterate over intermediate layers\n",
        "            for index in range(len(model.layers)-1):\n",
        "              layer = model.layers[index]\n",
        "              optimizer = optimizers[index]\n",
        "\n",
        "              # positive pass\n",
        "              pos_output = layer(pos_interm)\n",
        "              pos_goodness = model.goodness(pos_output)\n",
        "              pos_interm = model.ln(pos_output)\n",
        "              pos_interms.append(pos_interm.detach().clone())\n",
        "\n",
        "              # negative pass\n",
        "              neg_output = layer(neg_interm)\n",
        "              neg_goodness = model.goodness(neg_output)\n",
        "              neg_interm = model.ln(neg_output)\n",
        "              neg_interms.append(neg_interm.detach().clone())\n",
        "\n",
        "              # loss\n",
        "              loss = goodness_loss(pos_goodness,neg_goodness)\n",
        "\n",
        "              # update variables\n",
        "              total_pos_goodness[index] += pos_goodness\n",
        "              total_neg_goodness[index] += neg_goodness\n",
        "              total_loss[index] += loss\n",
        "\n",
        "              # clear gradients for this training step\n",
        "              optimizer.zero_grad()\n",
        "\n",
        "              # backpropagation, compute gradients\n",
        "              loss.backward()\n",
        "\n",
        "              # clip gradients to avoid exploding gradients\n",
        "              torch.nn.utils.clip_grad_norm_(parameters=layer.parameters(), max_norm=1,norm_type=2.0)\n",
        "\n",
        "              # apply gradient descent step\n",
        "              optimizer.step()\n",
        "\n",
        "              if (i+1) % 10000 == 0:\n",
        "                  print ('Layer {}, Epoch [{}/{}], Step [{}/{}], Positive Goodness: {:.4f}, Negative Goodness: {:.4f}, Loss: {:.4f}'\n",
        "                        .format(index, epoch + 1, num_epochs, i + 1, total_step, total_pos_goodness[index]/10000, total_neg_goodness[index]/10000, total_loss[index]/10000))\n",
        "                  total_pos_goodness[index],total_neg_goodness[index],total_loss[index] = 0,0,0\n",
        "\n",
        "            # output layer\n",
        "            final_input = torch.cat(pos_interms[1:],dim=1)\n",
        "            labels = model.layers[-1](final_input).reshape(-1)\n",
        "            loss = ceLoss(labels,label[0].to(device))\n",
        "            total_loss[-1] += loss\n",
        "\n",
        "            optimizers[-1].zero_grad()\n",
        "            loss.backward(retain_graph=True)\n",
        "            torch.nn.utils.clip_grad_norm_(parameters=model.layers[-1].parameters(), max_norm=1,norm_type=2.0)\n",
        "            optimizers[-1].step()\n",
        "\n",
        "            if (i+1) % 10000 == 0:\n",
        "              print ('Layer {}, Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "                    .format(index, epoch + 1, num_epochs, i + 1, total_step, total_loss[-1]/10000))\n",
        "              total_loss[-1] = 0\n",
        "\n",
        "            # return\n",
        "\n",
        "        pass\n",
        "\n",
        "    # save model every 5 epochs\n",
        "    if (epoch+1) % 5 == 0:\n",
        "        torch.save(model.state_dict(), 'model_v1.1_epoch{}.pth'.format(epoch+1))\n",
        "    pass\n",
        "num_epochs = 15\n",
        "train(num_epochs, model, loaders)"
      ],
      "metadata": {
        "id": "-ZLMO_AQ2Cj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# feature visualization\n",
        "model.layers[1].layer[1].weight.data[2][:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAYjc8TB2ssf",
        "outputId": "3bdfeee7-9050-40d9-b1ac-e5ffcc5522f6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.0196,  0.0037, -0.0153,  0.0152,  0.0039,  0.0120, -0.0058, -0.0118,\n",
              "         0.0085,  0.0028])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction test & visualization\n",
        "x,y = train_data[40][0].to(device), train_data[40][1]\n",
        "data = model.construct_supervised_example(x,y,False)\n",
        "print(\"Prediction: \", model.predict(data),\" Label: \",y)\n",
        "plt.imshow(data.squeeze().cpu(), cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "PMheoEy12rn2",
        "outputId": "f6460940-bbef-49f1-c5b5-33ba38555aff"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction:  8  Label:  1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAZIElEQVR4nO3df0xV9/3H8Rf+4GpbuBQRLreixR/VpSrLnDBiy3QSgS3GX1m06x+6NBotNlPWdmFZtbVL2FyyNV2Y7R+LrFm1rcnU1TQsFgtmHdhINcZsI0JYwQi4unEvoqCBz/cPv73rVdBevNc34PORfBK55xx49/SUZw/3co1zzjkBAHCPjbEeAABwfyJAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADAxDjrAW7W39+vCxcuKCEhQXFxcdbjAAAi5JxTV1eX/H6/xowZ/D5n2AXowoULysjIsB4DAHCXWltbNWXKlEG3D7sAJSQkWI+AGAoEAhEf4/V6YzAJgFi70/fzmD0HVF5erkcffVQTJkxQTk6OPvnkk690HD92G90SExMjXgBGpjt9P49JgN59912VlJRo586d+vTTT5WVlaWCggJdvHgxFl8OADASuRjIzs52xcXFoY/7+vqc3+93ZWVldzw2EAg4SaxRuobCemYWizW0FQgEbvvfdtTvgK5du6b6+nrl5+eHHhszZozy8/NVW1t7y/69vb0KBoNhCwAw+kU9QJ9//rn6+vqUlpYW9nhaWpra29tv2b+srExerze0eAUcANwfzH8RtbS0VIFAILRaW1utRwIA3ANRfxl2SkqKxo4dq46OjrDHOzo65PP5btnf4/HI4/FEewwAwDAX9Tug+Ph4LViwQFVVVaHH+vv7VVVVpdzc3Gh/OQDACBWTX0QtKSnR+vXr9c1vflPZ2dl67bXX1N3drR/+8Iex+HIAgBEoJgFau3at/v3vf2vHjh1qb2/X17/+dVVWVt7ywgQAwP0r7v9/z2LYCAaDvPUKAIwCgUDgtu9mYv4qOADA/YkAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwMc56AOB+9Oc//zniY5YvXx7xMc8++2zEx0jSnj17hnQcEAnugAAAJggQAMBE1AP08ssvKy4uLmzNmTMn2l8GADDCxeQ5oMcff1wffvjh/77IOJ5qAgCEi0kZxo0bJ5/PF4tPDQAYJWLyHNC5c+fk9/s1ffp0Pf3002ppaRl0397eXgWDwbAFABj9oh6gnJwcVVRUqLKyUnv27FFzc7OefPJJdXV1Dbh/WVmZvF5vaGVkZER7JADAMBT1ABUVFen73/++5s+fr4KCAn3wwQfq7OzUe++9N+D+paWlCgQCodXa2hrtkQAAw1DMXx2QlJSkxx57TI2NjQNu93g88ng8sR4DADDMxPz3gC5fvqympialp6fH+ksBAEaQqAfo+eefV01Njf71r3/pb3/7m1atWqWxY8fqqaeeivaXAgCMYFH/Edz58+f11FNP6dKlS5o8ebKeeOIJ1dXVafLkydH+UgCAESzOOeesh/iyYDAor9drPQbwlcXHx0d8zAcffBDxMUuWLIn4mHPnzkV8jCRlZ2dHfAy/QoGbBQIBJSYmDrqd94IDAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEzE/C+kA0a7CRMmRHzM7d6gMZpmzZo1pOMmTpwY8TG8GSkixR0QAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATPBu2MBd6u/vj/iYvr6+GExyq1dffXVIx/33v/+N8iTArbgDAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBM8GakwF2aOnVqxMdkZ2fHYJJbDWU2Sbp27VqUJwFuxR0QAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMBFxgI4fP67ly5fL7/crLi5Ohw4dCtvunNOOHTuUnp6uiRMnKj8/X+fOnYvWvACAUSLiAHV3dysrK0vl5eUDbt+9e7def/11vfHGGzpx4oQefPBBFRQUqKen566HBQCMHhH/jahFRUUqKioacJtzTq+99pp+9rOfacWKFZKkt956S2lpaTp06JDWrVt3d9MCAEaNqD4H1NzcrPb2duXn54ce83q9ysnJUW1t7YDH9Pb2KhgMhi0AwOgX1QC1t7dLktLS0sIeT0tLC227WVlZmbxeb2hlZGREcyQAwDBl/iq40tJSBQKB0GptbbUeCQBwD0Q1QD6fT5LU0dER9nhHR0do2808Ho8SExPDFgBg9ItqgDIzM+Xz+VRVVRV6LBgM6sSJE8rNzY3mlwIAjHARvwru8uXLamxsDH3c3Nys06dPKzk5WVOnTtW2bdv085//XLNmzVJmZqZeeukl+f1+rVy5MppzAwBGuIgDdPLkSS1ZsiT0cUlJiSRp/fr1qqio0Isvvqju7m5t2rRJnZ2deuKJJ1RZWakJEyZEb2oAwIgXcYAWL14s59yg2+Pi4rRr1y7t2rXrrgYDRort27dbjwCMSOavggMA3J8IEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgIuJ3wwYQbvz48dYjDKq7u9t6BGBQ3AEBAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACZ4M1JgFCsvL7ceARgUd0AAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAnejBT4kocffjjiY5YsWRKDSW71n//8J+Jjrl69GoNJgOjgDggAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMMGbkQJf4vF4Ij5mypQpMZjkVh9//HHEx3z22WcxmASIDu6AAAAmCBAAwETEATp+/LiWL18uv9+vuLg4HTp0KGz7hg0bFBcXF7YKCwujNS8AYJSIOEDd3d3KyspSeXn5oPsUFhaqra0ttPbv339XQwIARp+IX4RQVFSkoqKi2+7j8Xjk8/mGPBQAYPSLyXNA1dXVSk1N1ezZs7VlyxZdunRp0H17e3sVDAbDFgBg9It6gAoLC/XWW2+pqqpKv/zlL1VTU6OioiL19fUNuH9ZWZm8Xm9oZWRkRHskAMAwFPXfA1q3bl3oz/PmzdP8+fM1Y8YMVVdXa+nSpbfsX1paqpKSktDHwWCQCAHAfSDmL8OePn26UlJS1NjYOOB2j8ejxMTEsAUAGP1iHqDz58/r0qVLSk9Pj/WXAgCMIBH/CO7y5cthdzPNzc06ffq0kpOTlZycrFdeeUVr1qyRz+dTU1OTXnzxRc2cOVMFBQVRHRwAMLJFHKCTJ09qyZIloY+/eP5m/fr12rNnj86cOaM//OEP6uzslN/v17Jly/Tqq68O6T22AACjV8QBWrx4sZxzg27/y1/+clcDAQDuD7wXHADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADAxznoAAF9NMBi0HgGIKu6AAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATvBkp8CWpqanWIwzqzTfftB4BiCrugAAAJggQAMBERAEqKyvTwoULlZCQoNTUVK1cuVINDQ1h+/T09Ki4uFiTJk3SQw89pDVr1qijoyOqQwMARr6IAlRTU6Pi4mLV1dXp6NGjun79upYtW6bu7u7QPtu3b9f777+vAwcOqKamRhcuXNDq1aujPjgAYGSL6EUIlZWVYR9XVFQoNTVV9fX1ysvLUyAQ0O9//3vt27dP3/nOdyRJe/fu1de+9jXV1dXpW9/6VvQmBwCMaHf1HFAgEJAkJScnS5Lq6+t1/fp15efnh/aZM2eOpk6dqtra2gE/R29vr4LBYNgCAIx+Qw5Qf3+/tm3bpkWLFmnu3LmSpPb2dsXHxyspKSls37S0NLW3tw/4ecrKyuT1ekMrIyNjqCMBAEaQIQeouLhYZ8+e1TvvvHNXA5SWlioQCIRWa2vrXX0+AMDIMKRfRN26dauOHDmi48ePa8qUKaHHfT6frl27ps7OzrC7oI6ODvl8vgE/l8fjkcfjGcoYAIARLKI7IOectm7dqoMHD+rYsWPKzMwM275gwQKNHz9eVVVVoccaGhrU0tKi3Nzc6EwMABgVIroDKi4u1r59+3T48GElJCSEntfxer2aOHGivF6vnnnmGZWUlCg5OVmJiYl67rnnlJubyyvgAABhIgrQnj17JEmLFy8Oe3zv3r3asGGDJOk3v/mNxowZozVr1qi3t1cFBQX63e9+F5VhAQCjR0QBcs7dcZ8JEyaovLxc5eXlQx4KsPLF/0gBiD3eCw4AYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMjLMeALgf1dfX35NjgOGMOyAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwARvRgp8yYkTJ+7J16mpqYn4mJ6enhhMAtjhDggAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMBHnnHPWQ3xZMBiU1+u1HgMAcJcCgYASExMH3c4dEADABAECAJiIKEBlZWVauHChEhISlJqaqpUrV6qhoSFsn8WLFysuLi5sbd68OapDAwBGvogCVFNTo+LiYtXV1eno0aO6fv26li1bpu7u7rD9Nm7cqLa2ttDavXt3VIcGAIx8Ef2NqJWVlWEfV1RUKDU1VfX19crLyws9/sADD8jn80VnQgDAqHRXzwEFAgFJUnJyctjjb7/9tlJSUjR37lyVlpbqypUrg36O3t5eBYPBsAUAuA+4Ierr63Pf+9733KJFi8Ief/PNN11lZaU7c+aM++Mf/+geeeQRt2rVqkE/z86dO50kFovFYo2yFQgEbtuRIQdo8+bNbtq0aa61tfW2+1VVVTlJrrGxccDtPT09LhAIhFZra6v5SWOxWCzW3a87BSii54C+sHXrVh05ckTHjx/XlClTbrtvTk6OJKmxsVEzZsy4ZbvH45HH4xnKGACAESyiADnn9Nxzz+ngwYOqrq5WZmbmHY85ffq0JCk9PX1IAwIARqeIAlRcXKx9+/bp8OHDSkhIUHt7uyTJ6/Vq4sSJampq0r59+/Td735XkyZN0pkzZ7R9+3bl5eVp/vz5MfkHAACMUJE876NBfs63d+9e55xzLS0tLi8vzyUnJzuPx+NmzpzpXnjhhTv+HPDLAoGA+c8tWSwWi3X3607f+3kzUgBATPBmpACAYYkAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYGLYBcg5Zz0CACAK7vT9fNgFqKury3oEAEAU3On7eZwbZrcc/f39unDhghISEhQXFxe2LRgMKiMjQ62trUpMTDSa0B7n4QbOww2chxs4DzcMh/PgnFNXV5f8fr/GjBn8PmfcPZzpKxkzZoymTJly230SExPv6wvsC5yHGzgPN3AebuA83GB9Hrxe7x33GXY/ggMA3B8IEADAxIgKkMfj0c6dO+XxeKxHMcV5uIHzcAPn4QbOww0j6TwMuxchAADuDyPqDggAMHoQIACACQIEADBBgAAAJkZMgMrLy/Xoo49qwoQJysnJ0SeffGI90j338ssvKy4uLmzNmTPHeqyYO378uJYvXy6/36+4uDgdOnQobLtzTjt27FB6eromTpyo/Px8nTt3zmbYGLrTediwYcMt10dhYaHNsDFSVlamhQsXKiEhQampqVq5cqUaGhrC9unp6VFxcbEmTZqkhx56SGvWrFFHR4fRxLHxVc7D4sWLb7keNm/ebDTxwEZEgN59912VlJRo586d+vTTT5WVlaWCggJdvHjRerR77vHHH1dbW1to/fWvf7UeKea6u7uVlZWl8vLyAbfv3r1br7/+ut544w2dOHFCDz74oAoKCtTT03OPJ42tO50HSSosLAy7Pvbv338PJ4y9mpoaFRcXq66uTkePHtX169e1bNkydXd3h/bZvn273n//fR04cEA1NTW6cOGCVq9ebTh19H2V8yBJGzduDLsedu/ebTTxINwIkJ2d7YqLi0Mf9/X1Ob/f78rKygynuvd27tzpsrKyrMcwJckdPHgw9HF/f7/z+XzuV7/6Veixzs5O5/F43P79+w0mvDduPg/OObd+/Xq3YsUKk3msXLx40UlyNTU1zrkb/+7Hjx/vDhw4ENrnH//4h5PkamtrrcaMuZvPg3POffvb33Y/+tGP7Ib6Cob9HdC1a9dUX1+v/Pz80GNjxoxRfn6+amtrDSezce7cOfn9fk2fPl1PP/20WlparEcy1dzcrPb29rDrw+v1Kicn5768Pqqrq5WamqrZs2dry5YtunTpkvVIMRUIBCRJycnJkqT6+npdv3497HqYM2eOpk6dOqqvh5vPwxfefvttpaSkaO7cuSotLdWVK1csxhvUsHsz0pt9/vnn6uvrU1paWtjjaWlp+uc//2k0lY2cnBxVVFRo9uzZamtr0yuvvKInn3xSZ8+eVUJCgvV4Jtrb2yVpwOvji233i8LCQq1evVqZmZlqamrST3/6UxUVFam2tlZjx461Hi/q+vv7tW3bNi1atEhz586VdON6iI+PV1JSUti+o/l6GOg8SNIPfvADTZs2TX6/X2fOnNFPfvITNTQ06E9/+pPhtOGGfYDwP0VFRaE/z58/Xzk5OZo2bZree+89PfPMM4aTYThYt25d6M/z5s3T/PnzNWPGDFVXV2vp0qWGk8VGcXGxzp49e188D3o7g52HTZs2hf48b948paena+nSpWpqatKMGTPu9ZgDGvY/gktJSdHYsWNveRVLR0eHfD6f0VTDQ1JSkh577DE1NjZaj2Lmi2uA6+NW06dPV0pKyqi8PrZu3aojR47oo48+CvvrW3w+n65du6bOzs6w/Ufr9TDYeRhITk6OJA2r62HYByg+Pl4LFixQVVVV6LH+/n5VVVUpNzfXcDJ7ly9fVlNTk9LT061HMZOZmSmfzxd2fQSDQZ04ceK+vz7Onz+vS5cujarrwzmnrVu36uDBgzp27JgyMzPDti9YsEDjx48Pux4aGhrU0tIyqq6HO52HgZw+fVqShtf1YP0qiK/inXfecR6Px1VUVLi///3vbtOmTS4pKcm1t7dbj3ZP/fjHP3bV1dWuubnZffzxxy4/P9+lpKS4ixcvWo8WU11dXe7UqVPu1KlTTpL79a9/7U6dOuU+++wz55xzv/jFL1xSUpI7fPiwO3PmjFuxYoXLzMx0V69eNZ48um53Hrq6utzzzz/vamtrXXNzs/vwww/dN77xDTdr1izX09NjPXrUbNmyxXm9XlddXe3a2tpC68qVK6F9Nm/e7KZOneqOHTvmTp486XJzc11ubq7h1NF3p/PQ2Njodu3a5U6ePOmam5vd4cOH3fTp011eXp7x5OFGRICcc+63v/2tmzp1qouPj3fZ2dmurq7OeqR7bu3atS49Pd3Fx8e7Rx55xK1du9Y1NjZajxVzH330kZN0y1q/fr1z7sZLsV966SWXlpbmPB6PW7p0qWtoaLAdOgZudx6uXLnili1b5iZPnuzGjx/vpk2b5jZu3Djq/idtoH9+SW7v3r2hfa5eveqeffZZ9/DDD7sHHnjArVq1yrW1tdkNHQN3Og8tLS0uLy/PJScnO4/H42bOnOleeOEFFwgEbAe/CX8dAwDAxLB/DggAMDoRIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACb+D8/iM69DPmuZAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model evaluation using test set\n",
        "def test():\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for x, label in loaders['test']:\n",
        "            test_output = model.predict(x.to(device))\n",
        "            correct += (test_output == label)\n",
        "            total += 1\n",
        "    print('Test Accuracy of the model on the test set: %.2f' % (correct/total))"
      ],
      "metadata": {
        "id": "K5-yXqsh1-HP"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Previous Model Performance"
      ],
      "metadata": {
        "id": "KWYmB7jR9ZXz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('model_v1.pth',map_location=torch.device('cpu')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLzUiNdH9YWN",
        "outputId": "b2f6ff8d-b849-49e1-97b7-308e5cc99ccc"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# adjusted test function (label is messed up when model_v1)\n",
        "def test_v1():\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for x, label in loaders['test']:\n",
        "            test_output = model.predict(x.to(device)) + 1\n",
        "            if label == 0:\n",
        "              test_output -= 5\n",
        "            correct += (test_output == label)\n",
        "            total += 1\n",
        "    print()\n",
        "    print('Test Accuracy of the model on the test set: %.2f' % (correct/total))\n",
        "test_v1()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgSMzN_F-Ibw",
        "outputId": "886249df-924d-4661-967c-cf10206446b7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f129f0bc310>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Accuracy of the model on the test set: 0.65\n"
          ]
        }
      ]
    }
  ]
}